{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "The only preprocessing needed to train the BTC-USD prediction models is conversion of date to year, month & day.\n",
    "Since this has already been done in the last task and the preprocessed dataset is already available to us as a csv file, we dont need to do any further preprocessing. \n",
    "We can proceed to train the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model\n",
    "Linear regression is a fundamental statistical method used to model the relationship between one or more independent variables and a dependent variable. It assumes a linear relationship between the variables, where the goal is to find the best-fitting straight line that minimizes the difference between the predicted values and the actual observed values. The linear regression model is characterized by its simplicity and interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model saved as 'BTC-USD_regression_model.joblib'\n",
      "Mean Squared Error: 0.79\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "\n",
    "def train_regression_model(ticker, input_folder=\"Regression_data\"):\n",
    "    file_path = os.path.join(input_folder, f\"prep_{ticker}_data.csv\")\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        data = pd.read_csv(file_path)\n",
    "        \n",
    "        # Select features and target variable\n",
    "        features = ['Open', 'High', 'Low', 'Volume', 'Year', 'Month', 'Day']\n",
    "        target = 'Close'\n",
    "        \n",
    "        X = data[features]\n",
    "        y = data[target]\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Initialize and train a linear regression model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Save the trained model as a joblib file\n",
    "        model_filename = f\"{ticker}_regression_model.joblib\"\n",
    "        joblib.dump(model, model_filename)\n",
    "        print(f\"Trained model saved as '{model_filename}'\")\n",
    "        \n",
    "        # Predict on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate and print the Mean Squared Error\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "    else:\n",
    "        print(f\"Preprocessed data file for {ticker} not found.\")\n",
    "\n",
    "# Example usage\n",
    "ticker_to_train = 'BTC-USD'\n",
    "train_regression_model(ticker_to_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Linear Regression\n",
    "Mean Squared Error on Test Dataset: 0.79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor\n",
    "Random Forest is a versatile and powerful ensemble learning technique widely used in machine learning for both regression and classification tasks. Comprising an ensemble of decision trees, Random Forest combines the predictive strengths of multiple trees to create a robust and accurate model. Each decision tree in the forest is constructed using a random subset of the training data and a subset of features, introducing diversity and reducing the risk of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model saved as 'BTC-USD_random_forest_model.joblib'\n",
      "Mean Squared Error: 2.67\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "\n",
    "def train_random_forest_model(ticker, input_folder=\"Regression_data\"):\n",
    "    file_path = os.path.join(input_folder, f\"prep_{ticker}_data.csv\")\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        data = pd.read_csv(file_path)\n",
    "        \n",
    "        # Select features and target variable\n",
    "        features = ['Open', 'High', 'Low', 'Volume', 'Year', 'Month', 'Day']\n",
    "        target = 'Close'\n",
    "        \n",
    "        X = data[features]\n",
    "        y = data[target]\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Initialize and train a Random Forest regression model\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Save the trained model as a joblib file\n",
    "        model_filename = f\"{ticker}_random_forest_model.joblib\"\n",
    "        joblib.dump(model, model_filename)\n",
    "        print(f\"Random Forest model saved as '{model_filename}'\")\n",
    "        \n",
    "        # Predict on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate and print the Mean Squared Error\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "    else:\n",
    "        print(f\"Preprocessed data file for {ticker} not found.\")\n",
    "\n",
    "# Example usage\n",
    "ticker_to_train = 'BTC-USD'\n",
    "train_random_forest_model(ticker_to_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Random Forest Regressor\n",
    "Mean Squared Error on Test Dataset: 2.67\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting\n",
    "Gradient Boosting is a powerful machine learning technique that excels at building predictive models with high accuracy and flexibility. It falls under the ensemble learning umbrella and is known for its ability to sequentially improve upon the weaknesses of its predecessors in the ensemble, ultimately leading to a strong and accurate model.\n",
    "\n",
    "At its core, Gradient Boosting builds a predictive model by combining the predictions of multiple weak learners, often decision trees. Unlike Random Forest, which constructs trees in parallel, Gradient Boosting builds trees sequentially, with each new tree aiming to correct the errors made by the previous ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting model saved as 'BTC-USD_gradient_boosting_model.joblib'\n",
      "Mean Squared Error: 2.35\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "\n",
    "def train_gradient_boosting_model(ticker, input_folder=\"Regression_data\"):\n",
    "    file_path = os.path.join(input_folder, f\"prep_{ticker}_data.csv\")\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        data = pd.read_csv(file_path)\n",
    "        \n",
    "        # Select features and target variable\n",
    "        features = ['Open', 'High', 'Low', 'Volume', 'Year', 'Month', 'Day']\n",
    "        target = 'Close'\n",
    "        \n",
    "        X = data[features]\n",
    "        y = data[target]\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Initialize and train a Gradient Boosting regression model\n",
    "        model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Save the trained model as a joblib file\n",
    "        model_filename = f\"{ticker}_gradient_boosting_model.joblib\"\n",
    "        joblib.dump(model, model_filename)\n",
    "        print(f\"Gradient Boosting model saved as '{model_filename}'\")\n",
    "        \n",
    "        # Predict on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate and print the Mean Squared Error\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "    else:\n",
    "        print(f\"Preprocessed data file for {ticker} not found.\")\n",
    "\n",
    "# Example usage\n",
    "ticker_to_train = 'BTC-USD'\n",
    "train_gradient_boosting_model(ticker_to_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Gradient Boosting Model\n",
    "Mean Squared Error on Test Dataset: 2.35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model Recommendation\n",
    "\n",
    "1. Linear Regression Model: MSE= 0.79\n",
    "2. Random Forest Regressor: MSE= 2.67\n",
    "3. Gradient Boosting Model: MSE= 2.35\n",
    "\n",
    "From the above observations we can conclude that Linear Regression model is the best-suited for our purpose as it has the least MSE out of all 3 models.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
